{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7Eckh0QvPuM_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 09:24:01.407556: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-22 09:24:01.434872: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-22 09:24:01.435528: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-22 09:24:01.901688: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install matplotlib\n",
    "# !pip install pydot\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lKOAhDjfP92D"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from string import digits\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, dot, concatenate, Activation\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "76WPgbEsSeL6"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (Dense,Flatten,SimpleRNN,InputLayer,Conv1D,Bidirectional,GRU,LSTM,BatchNormalization,Dropout,Input, Embedding,TextVectorization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rZ_5BZJqQAle",
    "outputId": "a652d2a7-ebc9-474a-b8b3-25af8b2e26c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/MyDrive/hindi_english_parallel.csv.zip\n",
      "  inflating: /content/language/hindi_english_parallel.csv  \n"
     ]
    }
   ],
   "source": [
    "# # from google.colab import drive\n",
    "# # drive.mount('/content/drive')\n",
    "# !unzip /content/drive/MyDrive/hindi_english_parallel.csv.zip -d \"/content/language/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PRE_PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0uLVNRk5uG5I"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE=20000\n",
    "ENGLISH_SEQUENCE_LENGTH=32\n",
    "HINDI_SEQUENCE_LENGTH=32\n",
    "EMBEDDING_DIM=300\n",
    "BATCH_SIZE=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "1eikFqvnQEmh",
    "outputId": "43e80a6a-be37-489e-bd0d-c555ccee1c3b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hindi</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें</td>\n",
       "      <td>Give your application an accessibility workout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>एक्सेर्साइसर पहुंचनीयता अन्वेषक</td>\n",
       "      <td>Accerciser Accessibility Explorer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>निचले पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
       "      <td>The default plugin layout for the bottom panel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
       "      <td>The default plugin layout for the top panel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...</td>\n",
       "      <td>A list of plugins that are disabled by default</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               hindi  \\\n",
       "0    अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें   \n",
       "1                    एक्सेर्साइसर पहुंचनीयता अन्वेषक   \n",
       "2              निचले पटल के लिए डिफोल्ट प्लग-इन खाका   \n",
       "3               ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका   \n",
       "4  उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...   \n",
       "\n",
       "                                          english  \n",
       "0  Give your application an accessibility workout  \n",
       "1               Accerciser Accessibility Explorer  \n",
       "2  The default plugin layout for the bottom panel  \n",
       "3     The default plugin layout for the top panel  \n",
       "4  A list of plugins that are disabled by default  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "lines=pd.read_csv(\"hindi_english_parallel.csv\")\n",
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEEH-uDbSlEF",
    "outputId": "8d3bd412-6edf-43de-c1e1-76d2e82d51b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 2)\n"
     ]
    }
   ],
   "source": [
    "pd.isnull(lines).sum()\n",
    "lines.dropna(subset=['hindi', 'english'], inplace=True)\n",
    "pd.isnull(lines).sum()\n",
    "# len(lines)\n",
    "lines=lines.sample(n=20000,random_state=42)\n",
    "print(lines.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "n4zKoeQ6Sszk"
   },
   "outputs": [],
   "source": [
    "# Lowercase all characters\n",
    "lines.english=lines.english.map(lambda x : x.lower())\n",
    "lines.hindi=lines.hindi.apply(lambda x: x.lower())\n",
    "\n",
    "# Remove quotes\n",
    "lines.english=lines.english.apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines.hindi=lines.hindi.apply(lambda x: re.sub(\"'\", '', x))\n",
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "\n",
    "# Remove all the special characters\n",
    "lines.english=lines.english.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines.hindi=lines.hindi.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "\n",
    "# Remove extra spaces\n",
    "lines.english=lines.english.apply(lambda x: x.strip())\n",
    "lines.hindi=lines.hindi.apply(lambda x: x.strip())\n",
    "lines.english=lines.english.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines.hindi=lines.hindi.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "\n",
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines.english=lines.english.apply(lambda x: x.translate(remove_digits))\n",
    "lines.hindi = lines.hindi.apply(lambda x: re.sub(\"[२३०८१५७९४६0-9]\", \"\", x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7I2WAxdbSzfm"
   },
   "outputs": [],
   "source": [
    "def retain_hindi_alphabet(text):\n",
    "    return re.sub(r'[^\\u0900-\\u097F\\s]', '', text)\n",
    "def remove_words_with_numbers(text):\n",
    "    return re.sub(r'\\b[^a-zA-Z\\s]+\\b', '', text)\n",
    "def remove_specific_chars(text):\n",
    "    return re.sub(r'[ं]', '', text)\n",
    "\n",
    "# Apply the function to the 'hindi' column\n",
    "lines.hindi = lines.hindi.apply(retain_hindi_alphabet)\n",
    "lines.english = lines.english.apply(remove_words_with_numbers)\n",
    "#Apply the function to the 'hindi' column\n",
    "lines['hindi'] = lines['hindi'].apply(remove_specific_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Awt8idQSXvf8",
    "outputId": "1533bd5a-3ea8-4358-c4d1-33c30fd30aed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of Hindi Sentence  30\n",
      "maximum length of English Sentence  32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17589, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines['length_eng_sentence']=lines['english'].apply(lambda x:len(x.split(\" \")))\n",
    "lines['length_hin_sentence']=lines['hindi'].apply(lambda x:len(x.split(\" \")))\n",
    "lines=lines[lines['length_eng_sentence']<=ENGLISH_SEQUENCE_LENGTH]\n",
    "lines=lines[lines['length_hin_sentence']<=HINDI_SEQUENCE_LENGTH-2]\n",
    "print(\"maximum length of Hindi Sentence \",max(lines['length_hin_sentence']))\n",
    "print(\"maximum length of English Sentence \",max(lines['length_eng_sentence']))\n",
    "max_length_src=max(lines['length_hin_sentence'])\n",
    "max_length_tar=max(lines['length_eng_sentence'])\n",
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "NhnoNSLIS0fA",
    "outputId": "716ea6c5-48d6-47e1-caa9-ea117344358d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hindi</th>\n",
       "      <th>english</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136823</th>\n",
       "      <td>starttoken कृपया एक भिन्न नाम उपयोग करे endtoken</td>\n",
       "      <td>please use a different name</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783298</th>\n",
       "      <td>starttoken तेज endtoken</td>\n",
       "      <td>agile</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216571</th>\n",
       "      <td>starttoken एक अन्य परस्पर जुड़ा हुआ पहलू नवान्...</td>\n",
       "      <td>another inter linked aspect is that of innovat...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166305</th>\n",
       "      <td>starttoken  endtoken</td>\n",
       "      <td>attach the information to bug</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166752</th>\n",
       "      <td>starttoken कुछ राज्यो मे एक ऊपरी सदन है जिसे र...</td>\n",
       "      <td>certain states have an upper house also called...</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     hindi  \\\n",
       "136823    starttoken कृपया एक भिन्न नाम उपयोग करे endtoken   \n",
       "783298                             starttoken तेज endtoken   \n",
       "1216571  starttoken एक अन्य परस्पर जुड़ा हुआ पहलू नवान्...   \n",
       "166305                                starttoken  endtoken   \n",
       "1166752  starttoken कुछ राज्यो मे एक ऊपरी सदन है जिसे र...   \n",
       "\n",
       "                                                   english  \\\n",
       "136823                         please use a different name   \n",
       "783298                                               agile   \n",
       "1216571  another inter linked aspect is that of innovat...   \n",
       "166305                      attach the information to bug    \n",
       "1166752  certain states have an upper house also called...   \n",
       "\n",
       "         length_eng_sentence  length_hin_sentence  \n",
       "136823                     5                    6  \n",
       "783298                     1                    1  \n",
       "1216571                   10                   10  \n",
       "166305                     6                    1  \n",
       "1166752                   11                   14  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add start and end tokens to target sequences\n",
    "lines.hindi = lines.hindi.apply(lambda x : 'starttoken '+ x + ' endtoken')\n",
    "# lines.english = lines.english.apply(lambda x : 'starttoken '+ x + ' endtoken')\n",
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3H5AorgkV2hb",
    "outputId": "2f0d6100-8a9c-4659-fe00-8ad5448deb72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136823                 कृपया एक भिन्न नाम उपयोग करे endtoken\n",
       "783298                                          तेज endtoken\n",
       "1216571     एक अन्य परस्पर जुड़ा हुआ पहलू नवान्वेषण और उद...\n",
       "166305                                              endtoken\n",
       "1166752     कुछ राज्यो मे एक ऊपरी सदन है जिसे राज्य विधान...\n",
       "Name: hindi, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=lines.hindi.copy()\n",
    "output=output.apply(lambda x: re.sub(\"starttoken\", \"\", x))\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "HT0bxHr4SPDZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 09:24:51.096600: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-22 09:24:51.097068: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "english_vectorize_layer=TextVectorization(\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=ENGLISH_SEQUENCE_LENGTH\n",
    ")\n",
    "hindi_vectorize_layer=TextVectorization(\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=HINDI_SEQUENCE_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4xDCWjYvT5Nx"
   },
   "outputs": [],
   "source": [
    "english_vectorize_layer.adapt(lines.english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "kgrtLXxoUOhZ"
   },
   "outputs": [],
   "source": [
    "hindi_vectorize_layer.adapt(lines.hindi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "-SQ3r5-lYJ-j",
    "outputId": "0f175044-482f-4821-ddc6-f2b28a3bce38"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hindi</th>\n",
       "      <th>english</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136823</th>\n",
       "      <td>starttoken कृपया एक भिन्न नाम उपयोग करे</td>\n",
       "      <td>please use a different name</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783298</th>\n",
       "      <td>starttoken तेज</td>\n",
       "      <td>agile</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216571</th>\n",
       "      <td>starttoken एक अन्य परस्पर जुड़ा हुआ पहलू नवान्...</td>\n",
       "      <td>another inter linked aspect is that of innovat...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166305</th>\n",
       "      <td>starttoken</td>\n",
       "      <td>attach the information to bug</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166752</th>\n",
       "      <td>starttoken कुछ राज्यो मे एक ऊपरी सदन है जिसे र...</td>\n",
       "      <td>certain states have an upper house also called...</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     hindi  \\\n",
       "136823            starttoken कृपया एक भिन्न नाम उपयोग करे    \n",
       "783298                                     starttoken तेज    \n",
       "1216571  starttoken एक अन्य परस्पर जुड़ा हुआ पहलू नवान्...   \n",
       "166305                                        starttoken     \n",
       "1166752  starttoken कुछ राज्यो मे एक ऊपरी सदन है जिसे र...   \n",
       "\n",
       "                                                   english  \\\n",
       "136823                         please use a different name   \n",
       "783298                                               agile   \n",
       "1216571  another inter linked aspect is that of innovat...   \n",
       "166305                      attach the information to bug    \n",
       "1166752  certain states have an upper house also called...   \n",
       "\n",
       "         length_eng_sentence  length_hin_sentence  \n",
       "136823                     5                    6  \n",
       "783298                     1                    1  \n",
       "1216571                   10                   10  \n",
       "166305                     6                    1  \n",
       "1166752                   11                   14  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.hindi=lines.hindi.apply(lambda x: re.sub(\"endtoken\", \"\", x))\n",
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ApjNFyfxViPj"
   },
   "outputs": [],
   "source": [
    "def vectorizer(inputs,out):\n",
    "  return {'input_1':english_vectorize_layer(inputs['english']),\n",
    "          'input_2':hindi_vectorize_layer(inputs['hindi'])},hindi_vectorize_layer(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "vnv040HlqAyq"
   },
   "outputs": [],
   "source": [
    "dataset,output_sol=vectorizer(lines,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2-XSKSXY6DkF",
    "outputId": "3c6e206f-d9f8-4b55-8ac2-85eece120e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17589 17589 <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "# output_sol=output_sol.tolist()\n",
    "print(len(dataset['input_1']), len(output_sol),type(output_sol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Lqp1SmOex8n",
    "outputId": "bbed4793-73b4-4e9d-d2e6-552ccb56cae6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output_sol[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "UZMDWSUsc6yT"
   },
   "outputs": [],
   "source": [
    "def data_generator(train, output, batch_size=128):\n",
    "    while True:\n",
    "        num_samples = len(output)\n",
    "        for start_idx in range(0, num_samples, batch_size):\n",
    "            end_idx = start_idx + batch_size\n",
    "            batch_input_1 = train['input_1'][start_idx:end_idx]\n",
    "            batch_input_2 = train['input_2'][start_idx:end_idx]\n",
    "            batch_output = output[start_idx:end_idx]\n",
    "            yield (batch_input_1, batch_input_2), batch_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "vru-1fz_0xJc"
   },
   "outputs": [],
   "source": [
    "def valid_generator(train, output):\n",
    "  batch_input_1 = train['input_1'][0:]\n",
    "  batch_input_2 = train['input_2'][0:]\n",
    "  batch_output = output[0:]\n",
    "  return (batch_input_1, batch_input_2), batch_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XXgJb09l1KKE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "B9LVl7wgxUAG"
   },
   "outputs": [],
   "source": [
    "train_size = int(0.30 * len(dataset['input_1']))\n",
    "train_input_dict = {\n",
    "    'input_1': dataset['input_1'][:train_size],\n",
    "    'input_2': dataset['input_2'][:train_size]\n",
    "}\n",
    "train_output_list = output_sol[:train_size]\n",
    "\n",
    "validation_input_dict = {\n",
    "    'input_1': dataset['input_1'][train_size:],\n",
    "    'input_2': dataset['input_2'][train_size:]\n",
    "}\n",
    "validation_output_list = output_sol[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "anfgSf95bs3w",
    "outputId": "81aab86b-06bb-4f5a-f0c5-cf8eb060b160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5276 5276 12313\n"
     ]
    }
   ],
   "source": [
    "print(len(train_input_dict['input_1']), len(train_output_list),len(validation_output_list))\n",
    "# NUM_BATCHES=int(lines.shape[0]/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "jhbMpi0Ci8n6"
   },
   "outputs": [],
   "source": [
    "len_validation=len(validation_output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "o3pqQBYMb_yW"
   },
   "outputs": [],
   "source": [
    "len_train=len(train_input_dict['input_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C0f3mw-agEaA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PFX6l4YzcLk9",
    "outputId": "dec1e690-a60e-4f81-e238-4f3c6ddd2464"
   },
   "outputs": [],
   "source": [
    "### ENCODER\n",
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self,vocab_size,embedding_dim,units):\n",
    "    super(Encoder,self).__init__()\n",
    "    self.embedding_dim=embedding_dim\n",
    "    self.vocab_size=vocab_size\n",
    "    self.units=units\n",
    "\n",
    "  def build(self,input_shape):\n",
    "    self.embedding=Embedding(self.vocab_size,self.embedding_dim)\n",
    "    self.lstm=LSTM(self.units,return_sequences=True)\n",
    "\n",
    "  def call(self,x):\n",
    "    x=self.embedding(x)\n",
    "    output=self.lstm(x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32, 256)\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_UNITS=256\n",
    "EMBEDDING_DIM=256\n",
    "encoder=Encoder(VOCAB_SIZE,EMBEDDING_DIM,HIDDEN_UNITS)\n",
    "encoder_output=encoder(tf.zeros([128,ENGLISH_SEQUENCE_LENGTH]))\n",
    "print(encoder_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ATTENTION\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self,units):\n",
    "    super(BahdanauAttention,self).__init__()\n",
    "    self.units=units\n",
    "\n",
    "  def build(self,input_shape):\n",
    "    self.w_1=tf.keras.layers.Dense(self.units)\n",
    "    self.w_2=tf.keras.layers.Dense(self.units)\n",
    "    self.w=tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self,prev_dec_state,enc_states):\n",
    "    scores=self.w(\n",
    "        tf.nn.tanh(\n",
    "        self.w_1(tf.expand_dims(prev_dec_state,-2)) +\n",
    "        self.w_2(enc_states)))\n",
    "    \n",
    "    attention_weights=tf.nn.softmax(scores,axis=1)\n",
    "    context_vector=attention_weights*enc_states\n",
    "    context_vector=tf.reduce_sum(context_vector,axis=1)\n",
    "    return context_vector,attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32)\n",
      "(128, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "bahdanau_attention=BahdanauAttention(256)\n",
    "context_vector,attention_weights=bahdanau_attention(tf.zeros([128,32]),tf.zeros([128,ENGLISH_SEQUENCE_LENGTH,32]))\n",
    "print(context_vector.shape)\n",
    "print(attention_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "##DECORDER\n",
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self,vocab_size,embedding_dim,dec_units,sequence_length):\n",
    "    super(Decoder,self).__init__()\n",
    "    self.embedding_dim=embedding_dim\n",
    "    self.vocab_size=vocab_size\n",
    "    self.dec_units=dec_units\n",
    "    self.sequence_length=sequence_length\n",
    "   \n",
    "  def build(self,input_shape):\n",
    "    self.dense=Dense(self.vocab_size,activation=\"softmax\")\n",
    "    self.gru=GRU(\n",
    "        self.dec_units,return_sequences=True,return_state=True)\n",
    "    self.attention=BahdanauAttention(self.dec_units)\n",
    "    self.embedding=Embedding(self.vocab_size,self.embedding_dim)\n",
    "\n",
    "  def call(self,x,hidden,shifted_target):\n",
    "    outputs=[]\n",
    "    context_vectors=[]\n",
    "    attention_weightss=[]\n",
    "    shifted_target=self.embedding(shifted_target)\n",
    "    \n",
    "    for t in range(self.sequence_length):\n",
    "      context_vector,attention_weights=self.attention(hidden,x)\n",
    "      dec_input=context_vector+shifted_target[:,t]\n",
    "      output,hidden=self.gru(tf.expand_dims(dec_input,1))\n",
    "      outputs.append(output[:,0])\n",
    "\n",
    "    outputs=tf.convert_to_tensor(outputs)\n",
    "    outputs=tf.transpose(outputs, perm=[1,0,2])\n",
    "\n",
    "    outputs=self.dense(outputs)\n",
    "    return outputs,attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32, 20000)\n",
      "(128, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "decoder=Decoder(VOCAB_SIZE,EMBEDDING_DIM,HIDDEN_UNITS,HINDI_SEQUENCE_LENGTH)\n",
    "outputs,attention_weights=decoder(encoder_output,tf.zeros([128,HIDDEN_UNITS]),tf.zeros([128,HINDI_SEQUENCE_LENGTH]))\n",
    "print(outputs.shape)\n",
    "print(attention_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 32)]                 0         []                            \n",
      "                                                                                                  \n",
      " encoder_1 (Encoder)         (None, 32, 256)              5645312   ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 32)]                 0         []                            \n",
      "                                                                                                  \n",
      " decoder_1 (Decoder)         ((None, 32, 20000),          1078659   ['encoder_1[0][0]',           \n",
      "                              (None, 32, 1))              3          'input_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16431905 (62.68 MB)\n",
      "Trainable params: 16431905 (62.68 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### ENCODER\n",
    "input = Input(shape=(ENGLISH_SEQUENCE_LENGTH,), dtype=\"int64\", name=\"input_1\")\n",
    "encoder=Encoder(VOCAB_SIZE,EMBEDDING_DIM,HIDDEN_UNITS)\n",
    "encoder_output=encoder(input)\n",
    "\n",
    "### DECODER\n",
    "shifted_target=Input(shape=(HINDI_SEQUENCE_LENGTH,), dtype=\"int64\", name=\"input_2\")\n",
    "decoder=Decoder(VOCAB_SIZE,EMBEDDING_DIM,HIDDEN_UNITS,HINDI_SEQUENCE_LENGTH)\n",
    "decoder_output,attention_weightss=decoder(encoder_output,tf.zeros([1,HIDDEN_UNITS]),shifted_target)\n",
    "\n",
    "### OUTPUT\n",
    "bahdanau=Model([input,shifted_target],decoder_output)\n",
    "bahdanau.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "id": "1tMxfjlldTCL",
    "outputId": "e7199fd8-5c8f-400a-8e65-6f97488d609f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(bahdanau,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "Rg0uuKujcXA-"
   },
   "outputs": [],
   "source": [
    "class BLEU(tf.keras.metrics.Metric):\n",
    "    def __init__(self,name='bleu_score'):\n",
    "        super(BLEU,self).__init__()\n",
    "        self.bleu_score=0\n",
    "\n",
    "    def update_state(self,y_true,y_pred,sample_weight=None):\n",
    "      y_pred=tf.argmax(y_pred,-1)\n",
    "      self.bleu_score=0\n",
    "      for i,j in zip(y_pred,y_true):\n",
    "        tf.autograph.experimental.set_loop_options()\n",
    "\n",
    "        total_words=tf.math.count_nonzero(i)\n",
    "        total_matches=0\n",
    "        for word in i:\n",
    "          if word==0:\n",
    "            break\n",
    "          for q in range(len(j)):\n",
    "            if j[q]==0:\n",
    "              break\n",
    "            if word==j[q]:\n",
    "              total_matches+=1\n",
    "              j=tf.boolean_mask(j,[False if y==q else True for y in range(len(j))])\n",
    "              break\n",
    "\n",
    "        self.bleu_score+=total_matches/total_words\n",
    "\n",
    "    def result(self):\n",
    "        return self.bleu_score/BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "T8RZYGDecZEc"
   },
   "outputs": [],
   "source": [
    "bahdanau.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(5e-4),\n",
    "    metrics=[BLEU()],\n",
    "    run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "iTwMS_Vhcc3h"
   },
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'nmt_lstm_attention.h5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZQ6Mn0NfcrtZ",
    "outputId": "c40457cf-6613-4230-f2fd-da7b168e55f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method BLEU.update_state of <__main__.BLEU object at 0x7f0d2fc87610>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: not enough values to unpack (expected 2, got 0)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method BLEU.update_state of <__main__.BLEU object at 0x7f0d2fc87610>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: not enough values to unpack (expected 2, got 0)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   1325/Unknown - 5768s 4s/step - loss: 2.2772 - bleu: 0.3094"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator(train_input_dict, train_output_list, BATCH_SIZE)\n",
    "validation_generator = data_generator(validation_input_dict, validation_output_list,BATCH_SIZE)\n",
    "\n",
    "validation_data=validation_generator,\n",
    "history=bahdanau.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    callbacks=[model_checkpoint_callback],verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2v9DhnqrNGkZ"
   },
   "outputs": [],
   "source": [
    "index_to_word={x:y for x, y in zip(range(len(hindi_vectorize_layer.get_vocabulary())),\n",
    "                                   hindi_vectorize_layer.get_vocabulary())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5JXcNo4DNNc1"
   },
   "outputs": [],
   "source": [
    "def translator(english_sentence):\n",
    "  tokenized_english_sentence=english_vectorize_layer([english_sentence])\n",
    "  shifted_target='starttoken'\n",
    "\n",
    "  for i in range(FRENCH_SEQUENCE_LENGTH):\n",
    "    tokenized_shifted_target=french_vectorize_layer([shifted_target])\n",
    "    output=bahdanau.predict([tokenized_english_sentence,tokenized_shifted_target])\n",
    "    french_word_index=tf.argmax(output,axis=-1)[0][i].numpy()\n",
    "    current_word=index_to_word[french_word_index]\n",
    "    if current_word=='endtoken':\n",
    "      break\n",
    "    shifted_target+=' '+current_word\n",
    "  return shifted_target[11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "3DIv1hH_NZnL",
    "outputId": "95c149af-588b-4770-96af-9db27a230312"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'[UNK] के लिए [UNK] के लिए [UNK]'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator('the novel was published in book form in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "caP9e1K8NqYD"
   },
   "outputs": [],
   "source": [
    "word_to_index={y:x for x, y in zip(range(len(hindi_vectorize_layer.get_vocabulary())),\n",
    "                                   hindi_vectorize_layer.get_vocabulary())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5tqnKbQqN_BR",
    "outputId": "fffb9eaf-4599-4903-c226-9b1c82fe7b56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 17s 1s/step - loss: 2.1099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.109869956970215"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq_gru.evaluate(validation_generator)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
